# itau_Troubleshooting
Desafio Troubleshooting

## 1. Diagn√≥stico: Passos Imediatos

### 1.1 Verificar sa√∫de do cluster e pods

Checar se h√° throttling, falhas ou restart loops:

bash
~~~
kubectl -n payment get pods -o wide
kubectl -n payment describe pod <pod-name>
kubectl top pod -n payment
~~~

### 1.2 Observar m√©tricas e alertas no Grafana / Datadog

Dashboards de:

Lat√™ncia da API

Erro por c√≥digo HTTP

Conex√µes com banco de dados

Satura√ß√£o de CPU/Mem√≥ria

 ### 1.3 Analisar logs

 Ferramentas: Grafana Loki, Datadog Logs, kubectl logs

 Buscar por:

   - timeout

  - connection refused

  - slow query

  - pool exhausted


bash
~~~
kubectl logs -n payment -l app=payment-api --since=10m

~~~

###  1.4 Validar acesso ao banco (RDS)

Verificar:

  - Conectividade

  - Lat√™ncia de conex√£o

  - Erros de timeout na aplica√ß√£o

## 2. Ferramentas e Comandos
~~~
| Finalidade      | Ferramenta                    | Comando/uso                     |
| --------------- | ----------------------------- | ------------------------------- |
| M√©tricas        | Grafana / Datadog             | Dashboards + alertas            |
| Logs            | `kubectl logs`, Loki, Datadog | `--since=10m`                   |
| Pods e recursos | `kubectl`                     | `top`, `describe`, `get events` |
| APM             | OpenTelemetry, Datadog APM    | Traces por endpoint             |
| Banco de dados  | RDS Insights                  | Slow queries, conex√µes          |
| ArgoCD          | Argo UI / CLI                 | Confirmar estado da release     |

~~~

## 3. Hip√≥teses Prov√°veis

1. Problemas de conex√£o com RDS:

  - Exaust√£o de conex√µes

  - Lat√™ncia alta da VPC ou subnet

  - Lock em queries pesadas

2. Recursos saturados no pod ou cluster:

  - CPU/mem√≥ria insuficiente (throttling)

  -  Pool de conex√µes n√£o dimensionado

3. Picos de carga:
   
  - Tr√°fego aumentou sem escala proporcional
    
4. Problemas de rede (NAT, DNS, etc.):
   
  - NAT Gateway saturado (muito comum com RDS)

##  4. A√ß√µes Imediatas para Mitigar Impacto
~~~
| A√ß√£o                                         | Justificativa                                |
| -------------------------------------------- | -------------------------------------------- |
| Escalar r√©plicas de `payment-api`            | Reduz impacto e ajuda a atender tr√°fego      |
| Aumentar pool de conex√µes (se configur√°vel)  | Evitar timeout no acesso ao RDS              |
| Reiniciar pods com falha no acesso DB        | Liberar conex√µes presas                      |
| Investigar o RDS: slow queries e locks       | Aliviar gargalo real                         |
| Habilitar autoscaling (caso aplic√°vel)       | Lidar com carga flutuante                    |
| Rota fallback (ex: fila ou resposta default) | Se dispon√≠vel, garantir continuidade parcial |

~~~

## 5. Comunica√ß√£o Durante o Incidente
~~~
| Canal                  | Mensagem (exemplo)                                                                                                                       |
| ---------------------- | ---------------------------------------------------------------------------------------------------------------------------------------- |
| Slack #ops-alerts      | ‚Äúüö® Incidente em produ√ß√£o: `payment-api` com alta lat√™ncia (>2s) e erros de banco detectados. Investigando. Atualiza√ß√µes a cada 15 min.‚Äù |
| Atualiza√ß√µes regulares | Status do diagn√≥stico, a√ß√µes tomadas e pr√≥ximas etapas                                                                                   |
| Finaliza√ß√£o            | Causa raiz, impacto, mitiga√ß√£o e a√ß√µes preventivas                                                                                       |

~~~

##  6. Documenta√ß√£o P√≥s-Incidente (PIR - Post Incident Review)

### Sum√°rio

  - Servi√ßo afetado: payment-api

  - Ambiente: Produ√ß√£o

  - Data/Hora de in√≠cio e fim do incidente

  - Impacto: Processamento de pagamentos afetado

### Linha do tempo
~~~
| Hor√°rio | Evento                                            |
| ------- | ------------------------------------------------- |
| 10:05   | Alerta de lat√™ncia acionado                       |
| 10:10   | Logs indicam timeouts com RDS                     |
| 10:15   | Confirmado gargalo no pool de conex√µes            |
| 10:30   | Escaladas r√©plicas e aumentada capacidade do pool |
| 10:45   | Lat√™ncia estabilizada                             |

~~~

### Causa Raiz

Aumento de carga ‚Üí satura√ß√£o do pool de conex√µes com RDS ‚Üí timeouts

### Melhorias preventivas
~~~
| A√ß√£o                                      | Status     |
| ----------------------------------------- | ---------- |
| Implementar autoescalonamento de pods     | üîß A fazer |
| Monitorar m√©tricas de pool de conex√£o     | üîß A fazer |
| Aumentar limite e timeout do DB           | ‚úÖ Feito    |
| Dashboards com alertas de satura√ß√£o de DB | ‚úÖ Feito    |
| Configurar fallback para erro de DB       | üîß A fazer |

~~~

## Modelo de Incidente

### Resumo do Incidente
~~~
- **Servi√ßo impactado:** `payment-api`
- **Ambiente:** Produ√ß√£o (`EKS-prod`)
- **Namespace:** `payment`
- **Data/Hora de In√≠cio:** YYYY-MM-DD HH:MM
- **Data/Hora de Fim:** YYYY-MM-DD HH:MM
- **Dura√ß√£o:** XX minutos
- **Impacto:** Alta lat√™ncia e falhas no processamento de pagamentos. Servi√ßo apresentou >2s de resposta por 10 minutos.

~~~

### Linha do Tempo
~~~
| Hor√°rio | Evento |
|--------|--------|
| 10:05  | Alerta de lat√™ncia da API acionado (> 2s por 10min) |
| 10:10  | Logs mostram timeout na comunica√ß√£o com RDS |
| 10:15  | Confirmado gargalo no pool de conex√µes com RDS |
| 10:30  | Escalado n√∫mero de r√©plicas + ajuste do pool |
| 10:45  | M√©tricas estabilizadas, lat√™ncia voltou ao normal |
~~~

### Causa Raiz

 Aumento de carga inesperado levou √† satura√ß√£o do pool de conex√µes com o banco RDS. Como consequ√™ncia, a aplica√ß√£o apresentou timeouts e aumento expressivo na lat√™ncia m√©dia das requisi√ß√µes HTTP.

 ### Detec√ß√£o
~~~
- Alerta autom√°tico de **lat√™ncia m√©dia > 2s**
- Logs com erros `timeout` ao acessar banco
- Traces via OpenTelemetry mostraram atraso no acesso a servi√ßos externos
~~~
 
### A√ß√µes Tomadas
~~~
| A√ß√£o | Status |
|------|--------|
| Verifica√ß√£o de pods e m√©tricas de recursos | ‚úÖ |
| Escalonamento das r√©plicas de `payment-api` | ‚úÖ |
| Ajuste no pool de conex√µes da aplica√ß√£o | ‚úÖ |
| Verifica√ß√£o de locks/slow queries no RDS | ‚úÖ |
| An√°lise de logs e traces distribu√≠dos | ‚úÖ |
~~~

### Hip√≥teses Verificadas
~~~
- [x] Satura√ß√£o do pool de conex√µes com RDS
- [ ] Problemas na rede (NAT Gateway)
- [ ] Mudan√ßa recente no c√≥digo (n√£o houve)
- [ ] Sobrecarga de CPU/mem√≥ria
~~~

### Li√ß√µes Aprendidas
~~~
- A satura√ß√£o de banco √© silenciosa, mas cr√≠tica
- M√©tricas de conex√£o com banco n√£o estavam sendo monitoradas
- Escalabilidade horizontal ajudou, mas o gargalo era o pool fixo
~~~

### Melhorias Preventivas
~~~
| A√ß√£o Preventiva | Status |
|-----------------|--------|
| Adicionar monitoramento do uso do pool de conex√µes | üîß A fazer |
| Habilitar HPA baseado em lat√™ncia | üîß A fazer |
| Melhorar limites de recurso dos pods | ‚úÖ Feito |
| Implementar fallback para falha no banco | üîß A fazer |
| Adicionar alertas para `DBConnectionTimeout` | ‚úÖ Feito |
~~~

### Comunica√ß√£o
~~~
- Canal: `#ops-alerts`, reuni√µes de status a cada 15 minutos
- Atualiza√ß√µes cont√≠nuas foram enviadas at√© a normaliza√ß√£o
- Incidente compartilhado com time de engenharia e SRE
~~~

### Artefatos Relacionados
~~~
- Logs e m√©tricas no Grafana: [link]
- Traces de requisi√ß√µes: [link]
- Pull request de ajuste do pool: [link]
- Configura√ß√£o ArgoCD: [link]
~~~

**Revisado por:** Alexandre Jos√© Batista  
**Data:** 14/07/2025

